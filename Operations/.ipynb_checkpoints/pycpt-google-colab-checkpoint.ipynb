{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c986233",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# PyCPT Version 2 - Google Colab\n",
    "\n",
    "This is the current operational PyCPT seasonal climate forecasting workflow. This notebook can be adapted to suit your exact needs through modifications of the code. This notebook uses PyCPT v2 utilities to \n",
    "\n",
    "1. download data from the IRI Data Library (through the CPT-DL python library) \n",
    "2. Run bias-correction using the IRI Climate Predictability Tool (through its companion python library, CPT-CORE) \n",
    "3. Plot skills scores and spatial loadings\n",
    "4. Produce a multi-model ensemble forecast by taking the simple average of the bias-corrected members\n",
    "5. Plots skill scores, deterministic forecasts, probabilistic forecasts, and exceedance probabilities for this NextGen MME forecast. \n",
    "\n",
    "This version of the notebook is modified for compatibility with Google Co-Lab (colab.research.google.com/) and is all executed in a single cell (except for set up) to make managing the environment possible. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094962d",
   "metadata": {},
   "source": [
    "### This cell installs Anaconda on Google Colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8eab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08021f6",
   "metadata": {},
   "source": [
    "### This cell uses conda to create the pycpt environment and install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfeb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create -c iri-nextgen -c conda-forge -n pycpt_env pycpt gfortran_linux-64 make \n",
    "!mamba install -q -c conda-forge cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933472af",
   "metadata": {},
   "source": [
    "### This Cell is all the analysis of PyCPT - results are saved into files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb2b87",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOADING OBSERVATIONS\n",
      "URL: https://iridl.ldeo.columbia.edu/SOURCES/.UCSB/.CHIRPS/.v2p0/.daily-improved/.global/.0p25/.prcp/92/mul/T/(1%20Jan%201982)/(31%20Dec%202010)/RANGE/T/%28Jun-Aug%201982-2010%29/seasonalAverage/Y/%285%29/%2830%29/RANGEEDGES/X/%2870%29/%2890%29/RANGEEDGES/-999/setmissing_value/%5BX/Y%5D%5BT%5Dcptv10.tsv\n",
      "\n",
      "DOWNLOADING: [**********************   ] (453 KB) 0:01:15.874964\r"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "source activate pycpt \n",
    "python\n",
    "\n",
    "import cptdl as dl \n",
    "import cptio as cio \n",
    "import cptcore as cc \n",
    "import cptextras as ce \n",
    "\n",
    "import xarray as xr \n",
    "import datetime as dt \n",
    "from pathlib import Path \n",
    "import matplotlib.pyplot as plt \n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "\n",
    "case_directory = Path.home() / \"Desktop\" / \"pycpt_debugging\"\n",
    "case_directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# POE settings \n",
    "threshold = 0.5 \n",
    "isPercentile = True\n",
    "point_latitude = 16\n",
    "point_longitude = 78\n",
    "\n",
    "MOS = 'CCA' # must be one of 'CCA', 'PCR', or \"None\"\n",
    "predictor_names = ['CFSv2.PRCP','GEOSS2S.PRCP' ]\n",
    "predictand_name = 'UCSB.PRCP'\n",
    "\n",
    "# use dl.observations.keys() to see all options for predictand \n",
    "# and dl.hindcasts.keys() to see all options for predictors\n",
    "# make sure your first_year & final_year are compatible with \n",
    "# your selections for your predictors and predictands \n",
    "\n",
    "download_args = { \n",
    "   # 'fdate':\n",
    "   #   the initialization date of the model forecasts / hindcasts\n",
    "   #   this field is defined by a python datetime.datetime object\n",
    "   #   for example: dt.datetime(2022, 5, 1) # YYYY, MM, DD as integers\n",
    "   #   The year field is only used for forecasts, otherwise ignored\n",
    "   #   The day field is only used in subseasonal forecasts, otherwise ignored\n",
    "   #   The month field is an integer representing a month - ie, May=5\n",
    "  'fdate': dt.datetime(2022, 5, 1),  \n",
    "    \n",
    "   # 'first_year':\n",
    "   #   the first year of hindcasts you want. **NOT ALL MODELS HAVE ALL YEARS**\n",
    "   #   double check that your model has hindcast data for all years in [first_year, final_year]\n",
    "   #   This field is defined by a python integer representing a year, ie: 1993\n",
    "  'first_year': 1982, \n",
    "    \n",
    "   # 'final_year':\n",
    "   #   the final year of hindcasts you want. **NOT ALL MODELS HAVE ALL YEARS**\n",
    "   #   double check that your model has hindcast data for all years in [first_year, final_year]\n",
    "   #   This field is defined by a python integer representing a year, ie: 2016\n",
    "  'final_year': 2010, \n",
    "    \n",
    "   # 'predictor_extent':\n",
    "   #   The geographic bounding box of the climate model data you want to download\n",
    "   #   This field is defined by a python dictionary with the keys \"north\", \"south\",\n",
    "   #   \"east\", and \"west\", each of which maps to a python integer representing the \n",
    "   #   edge of a bounding box. i.e., \"north\" will be the northernmost boundary,\n",
    "   #   \"south\" the southernmost boundary. Example: {\"north\": 90, \"south\": 90, \"east\": 0, \"west\": 180}\n",
    "  'predictor_extent': {\n",
    "    'east': 100,\n",
    "    'west': 60, \n",
    "    'north': 35, \n",
    "    'south': 0\n",
    "  }, \n",
    "    \n",
    "   # 'predictand_extent':\n",
    "   #   The geographic bounding box of the observation data you want to download\n",
    "   #   This field is defined by a python dictionary with the keys \"north\", \"south\",\n",
    "   #   \"east\", and \"west\", each of which maps to a python integer representing the \n",
    "   #   edge of a bounding box. i.e., \"north\" will be the northernmost boundary,\n",
    "   #   \"south\" the southernmost boundary. Example: {\"north\": 90, \"south\": 90, \"east\": 0, \"west\": 180}\n",
    "  'predictand_extent': {\n",
    "    'east': 90,\n",
    "    'west': 70, \n",
    "    'north': 30, \n",
    "    'south': 5\n",
    "  }, \n",
    "    \n",
    "   # 'lead_low': \n",
    "   #   the number of months from the first of the initialization month to the center of \n",
    "   #   the first month included in the target period. Always an integer + 0.5. \n",
    "   #   this field is defined by a python floating point number \n",
    "   #   for example  a lead-1 forecast would use lead_low=1.5, if you want init=may, target=Jun-..\n",
    "  'lead_low': 1.5,\n",
    "    \n",
    "   # 'lead_high': \n",
    "   #   the number of months from the first of the initialization month to the center of \n",
    "   #   the last month included in the target period. Always an integer + 0.5. \n",
    "   #   this field is defined by a python floating point number \n",
    "   #   for example  a forecast initialized in may, whose target period ended in Aug, \n",
    "   #   would use lead_high=3.5\n",
    "  'lead_high': 3.5, \n",
    "    \n",
    "   # 'target': \n",
    "   #   Mmm-Mmm indicating the months included in the target period of the forecast. \n",
    "   #   this field is defined by a python string, with two three-letter month name abbreviations \n",
    "   #   whose first letters are capitalized, and all other letters are lowercase\n",
    "   #   and who are separated by a dash character. \n",
    "   #   for example, if you wanted a JJA target period, you would use 'Jun-Aug'\n",
    "  'target': 'Jun-Aug',\n",
    "    \n",
    "   # 'filetype':\n",
    "   #   the filetype to be downloaded. for now, it saves a lot of headache just to set this equal\n",
    "   #   to 'cptv10.tsv' which is a boutique plain-text CPT filetype based on .tsv + metadata\n",
    "  'filetype': 'cptv10.tsv'\n",
    "}\n",
    "\n",
    "cpt_args = { \n",
    "    'transform_predictand': 'Empirical',  # transformation to apply to the predictand dataset - None, 'Empirical', 'Gamma'\n",
    "    'tailoring': None,  # tailoring None, Anomaly, StdAnomaly, or SPI (SPI only available on Gamma)\n",
    "    'cca_modes': (1,6), # minimum and maximum of allowed CCA modes \n",
    "    'x_eof_modes': (1,8), # minimum and maximum of allowed X Principal Componenets \n",
    "    'y_eof_modes': (1,6), # minimum and maximum of allowed Y Principal Components \n",
    "    'validation': 'crossvalidation', # the type of validation to use - crossvalidation, retroactive, or doublecrossvalidation\n",
    "    'drymask': False, #whether or not to use a drymask of -999\n",
    "    'scree': True, # whether or not to save % explained variance for eof modes\n",
    "    'crossvalidation_window': 5,  # number of samples to leave out in each cross-validation step \n",
    "    'synchronous_predictors': True, # whether or not we are using 'synchronous predictors'\n",
    "}\n",
    "\n",
    "\n",
    "force_download = False\n",
    "\n",
    "print(\"DOWNLOADING OBSERVATIONS\")\n",
    "if not Path(case_directory / '{}.nc'.format(predictand_name)).is_file() or force_download:\n",
    "    Y = dl.download(dl.observations[predictand_name], case_directory / (predictand_name +'.tsv'), **download_args, verbose=True, use_dlauth=False)\n",
    "    Y = getattr(Y, [i for i in Y.data_vars][0])\n",
    "    Y.to_netcdf(case_directory / '{}.nc'.format(predictand_name))\n",
    "else:\n",
    "    Y = xr.open_dataset(case_directory / '{}.nc'.format(predictand_name))\n",
    "    Y = getattr(Y, [i for i in Y.data_vars][0])\n",
    "    \n",
    "print('\\n DOWNLOADING PREDICTORS (GCMS)')\n",
    "# download training data \n",
    "hindcast_data = []\n",
    "for model in predictor_names: \n",
    "    if not Path(case_directory / (model + '.nc')).is_file() or force_download:\n",
    "        X = dl.download(dl.hindcasts[model],case_directory / ( model+'.tsv'), **download_args, verbose=True, use_dlauth=False)\n",
    "        X = getattr(X, [i for i in X.data_vars][0])\n",
    "        X.name = Y.name\n",
    "        X.to_netcdf(case_directory / '{}.nc'.format(model))\n",
    "    else:\n",
    "        X = xr.open_dataset(case_directory / (model + '.nc'))\n",
    "        X = getattr(X, [i for i in X.data_vars][0])\n",
    "        X.name = Y.name\n",
    "    hindcast_data.append(X)\n",
    "    \n",
    "print('\\n DOWNLOADING REAL-TIME PREDICTORS (GCM Real Time Forecasts)')\n",
    "# download forecast data \n",
    "forecast_data = []\n",
    "for model in predictor_names: \n",
    "    if not Path(case_directory / (model + '_f.nc')).is_file() or force_download:\n",
    "        F = dl.download(dl.forecasts[model], case_directory / (model+'_f.tsv'), **download_args, verbose=True, use_dlauth=False)\n",
    "        F = getattr(F, [i for i in F.data_vars][0])\n",
    "        F.name = Y.name\n",
    "        F.to_netcdf(case_directory / (model + '_f.nc'))\n",
    "    else:\n",
    "        F = xr.open_dataset(case_directory / (model + '_f.nc'))\n",
    "        F = getattr(F, [i for i in F.data_vars][0])\n",
    "        F.name = Y.name\n",
    "    forecast_data.append(F)\n",
    "    \n",
    "print('\\n PERFORMING CPT ANALYSES\\n')\n",
    "hcsts, fcsts, skill, pxs, pys = [], [], [], [], []\n",
    "\n",
    "for i, model_hcst in enumerate(hindcast_data):\n",
    "    print('BIAS-CORRECTING {}'.format(predictor_names[i]))\n",
    "    \n",
    "    if str(MOS).upper() == 'CCA':\n",
    "        \n",
    "        # fit CCA model between X & Y and produce real-time forecasts for F \n",
    "        cca_h, cca_rtf, cca_s, cca_px, cca_py = cc.canonical_correlation_analysis(model_hcst, Y, F=forecast_data[i], **cpt_args)\n",
    "        print(' - Produced deterministic hindcasts, real-time prob/def forecast, deterministic skill, and patterns')\n",
    "        # fit CCA model again between X & Y, and produce in-sample probabilistic hindcasts \n",
    "        # this is using X in place of F, with the year coordinates changed to n+100 years\n",
    "        # because CPT does not allow you to make forecasts for in-sample data\n",
    "        cca_h, cca_f, cca_s, cca_px, cca_py = cc.canonical_correlation_analysis(model_hcst, Y, F=ce.redate(model_hcst), **cpt_args)\n",
    "        print(' - Produced In-Sample (NOT CROSS-VALIDATED) Probabilistic Hindcasts')\n",
    "        cca_h = xr.merge([cca_h, ce.redate(cca_f.probabilistic, yeardelta=-100), ce.redate(cca_f.prediction_error_variance, yeardelta=-100)])\n",
    "        \n",
    "        # use the in-sample probabilistic hindcasts to perform probabilistic forecast verification\n",
    "        # warning - this produces unrealistically optimistic values \n",
    "        cca_pfv = cc.probabilistic_forecast_verification(cca_h.probabilistic, Y, **cpt_args)\n",
    "        print(' - Produced In-Sample (NOT CROSSVALIDATED) Probabilistic Skill Scores')\n",
    "        cca_s = xr.merge([cca_s, cca_pfv])\n",
    "        hcsts.append(cca_h)\n",
    "        fcsts.append(cca_rtf)\n",
    "        skill.append(cca_s.where(cca_s > -999, other=np.nan))\n",
    "        pxs.append(cca_px)\n",
    "        pys.append(cca_py)\n",
    "        \n",
    "    elif str(MOS).upper() == 'PCR':\n",
    "        \n",
    "        # fit PCR model between X & Y and produce real-time forecasts for F \n",
    "        pcr_h, pcr_rtf, pcr_s, pcr_px = cc.principal_components_regression(model_hcst, Y, F=forecast_data[i], **cpt_args)\n",
    "        print(' - Produced deterministic hindcasts, real-time prob/def forecast, deterministic skill, and patterns')\n",
    "        # fit PCR model again between X & Y, and produce in-sample probabilistic hindcasts \n",
    "        # this is using X in place of F, with the year coordinates changed to n+100 years\n",
    "        # because CPT does not allow you to make forecasts for in-sample data\n",
    "        pcr_h, pcr_f, pcr_s, pcr_px = cc.principal_components_regression(model_hcst, Y, F=ce.redate(model_hcst), **cpt_args)\n",
    "        print(' - Produced In-Sample (NOT CROSS-VALIDATED) Probabilistic Hindcasts')\n",
    "        pcr_h = xr.merge([pcr_h, ce.redate(pcr_f.probabilistic, yeardelta=-100), ce.redate(pcr_f.prediction_error_variance, yeardelta=-100)])\n",
    "        \n",
    "        # use the in-sample probabilistic hindcasts to perform probabilistic forecast verification\n",
    "        # warning - this produces unrealistically optimistic values \n",
    "        pcr_pfv = cc.probabilistic_forecast_verification(pcr_h.probabilistic, Y, **cpt_args)\n",
    "        print(' - Produced In-Sample (NOT CROSSVALIDATED) Probabilistic Skill Scores')\n",
    "        hcsts.append(pcr_h)\n",
    "        fcsts.append(pcr_rtf)\n",
    "        skill.append(pcr_s.where(pcr_s > -999, other=np.nan))\n",
    "        pxs.append(pcr_px)\n",
    "    else:\n",
    "        # simply compute deterministic skill scores of non-corrected ensemble means \n",
    "        nomos_skill = cc.deterministic_skill(model_hcst, Y, **cpt_args)\n",
    "        skill.append(nomos_skill.where(nomos_skill > -999, other=np.nan))\n",
    "        print(' - Produced Deterministic Skill Scores ')\n",
    "        \n",
    "    # choose what data to export here (any of the above results data arrays can be saved to netcdf)\n",
    "    if str(MOS).upper() == 'CCA':\n",
    "        cca_h.to_netcdf(case_directory /  (predictor_names[i] + '_crossvalidated_cca_hindcasts.nc'))\n",
    "        cca_rtf.to_netcdf(case_directory / (predictor_names[i] + '_realtime_cca_forecasts.nc'))\n",
    "        cca_s.to_netcdf(case_directory / (predictor_names[i] + '_skillscores_cca.nc'))\n",
    "        cca_px.to_netcdf(case_directory / (predictor_names[i] + '_cca_x_spatial_loadings.nc'))\n",
    "        cca_py.to_netcdf(case_directory / (predictor_names[i] + '_cca_y_spatial_loadings.nc'))\n",
    "    elif str(MOS).upper() == 'PCR':\n",
    "        pcr_h.to_netcdf(case_directory /  (predictor_names[i] + '_crossvalidated_pcr_hindcasts.nc'))\n",
    "        pcr_rtf.to_netcdf(case_directory / (predictor_names[i] + '_realtime_pcr_forecasts.nc'))\n",
    "        pcr_s.to_netcdf(case_directory / (predictor_names[i] + '_skillscores_pcr.nc'))\n",
    "        pcr_px.to_netcdf(case_directory / (predictor_names[i] + '_pcr_x_spatial_loadings.nc'))\n",
    "    else: \n",
    "        nomos_skill.to_netcdf(case_directory / (predictor_names[i] + '_nomos_skillscores.nc'))\n",
    "    print(' - Saved Data to {}'.format(case_directory.absolute()))\n",
    "    \n",
    "     \n",
    "\n",
    "print('\\nCOMPUTING MULTI-MODEL ENSEMBLE')\n",
    "#ensemble = ['SEAS5.PRCP','SPEAR.PRCP',  'CanSIPSIC3.PRCP' ]\n",
    "ensemble = predictor_names\n",
    "\n",
    "### Do not modify below\n",
    "\n",
    "det_fcst = []\n",
    "det_hcst = []\n",
    "pr_fcst = []\n",
    "pr_hcst = []\n",
    "pev_fcst = []\n",
    "pev_hcst = []\n",
    "for model in ensemble:\n",
    "    assert model in predictor_names, \"all members of the nextgen ensemble must be in predictor_names - {} is not\".format(model)\n",
    "    ndx = predictor_names.index(model)\n",
    "    \n",
    "    det_fcst.append(fcsts[ndx].deterministic)\n",
    "    det_hcst.append(hcsts[ndx].deterministic)\n",
    "    pr_fcst.append(fcsts[ndx].probabilistic)\n",
    "    pr_hcst.append(hcsts[ndx].probabilistic)\n",
    "    pev_fcst.append(fcsts[ndx].prediction_error_variance)\n",
    "    pev_hcst.append(hcsts[ndx].prediction_error_variance)\n",
    "\n",
    "det_fcst = xr.concat(det_fcst, 'model').mean('model')\n",
    "det_hcst = xr.concat(det_hcst, 'model').mean('model')\n",
    "pr_fcst = xr.concat(pr_fcst, 'model').mean('model')\n",
    "pr_hcst = xr.concat(pr_hcst, 'model').mean('model')\n",
    "pev_fcst = xr.concat(pev_fcst, 'model').mean('model')\n",
    "pev_hcst = xr.concat(pev_hcst, 'model').mean('model')\n",
    "\n",
    "det_fcst.to_netcdf(case_directory / ('nextgen_deterministic_forecast.nc'))\n",
    "det_hcst.to_netcdf(case_directory / ('nextgen_deterministic_hindcast.nc'))\n",
    "pr_fcst.to_netcdf(case_directory / ('nextgen_probabilistic_forecast.nc'))\n",
    "pr_hcst.to_netcdf(case_directory / ('nextgen_probabilistic_hindcast.nc'))\n",
    "pev_fcst.to_netcdf(case_directory / ('nextgen_prediction_error_variance_forecast.nc'))\n",
    "pev_hcst.to_netcdf(case_directory / ('nextgen_prediction_error_variance_hindcast.nc'))\n",
    "\n",
    "\n",
    "print(' - computed ensembles of forecast mean, prediction error variance, and tercile probabilities')\n",
    "\n",
    "det_hcst.attrs['missing'] = hcsts[0].attrs['missing']\n",
    "det_hcst.attrs['units'] = hcsts[0].attrs['units']\n",
    "\n",
    "pr_hcst.attrs['missing'] = hcsts[0].attrs['missing']\n",
    "pr_hcst.attrs['units'] = hcsts[0].attrs['units']\n",
    "\n",
    "\n",
    "nextgen_skill_deterministic = cc.deterministic_skill(det_hcst, Y, **cpt_args)\n",
    "print(' - computed deterministic skill of ensemble ')\n",
    "nextgen_skill_probabilistic = cc.probabilistic_forecast_verification(pr_hcst, Y, **cpt_args)\n",
    "print(' - computed probabilistic skill of ensemble ')\n",
    "nextgen_skill = xr.merge([nextgen_skill_deterministic, nextgen_skill_probabilistic])\n",
    "\n",
    "nextgen_skill.to_netcdf(case_directory / ('nextgen_skillscores.nc'))\n",
    "\n",
    "\n",
    "\n",
    "print('\\nCOMPUTING PROBABILITY OF EXCEEDANCE')\n",
    "\n",
    "\n",
    "## DO not modify below\n",
    "\n",
    "# Define transformer based on transform_predictand setting\n",
    "if MOS =='CCA':\n",
    "    if str(cpt_args['transform_predictand']).upper() == 'GAMMA':\n",
    "        transformer = ce.GammaTransformer()\n",
    "    elif str(cpt_args['transform_predictand']).upper() == 'EMPIRICAL':\n",
    "        transformer = ce.EmpiricalTransformer()\n",
    "    else:\n",
    "        transformer = None\n",
    "elif MOS == 'PCR':\n",
    "    if str(cpt_args['transform_predictand']).upper() == 'GAMMA':\n",
    "        transformer = ce.GammaTransformer()\n",
    "    elif str(cpt_args['transform_predictand']).upper() == 'EMPIRICAL':\n",
    "        transformer = ce.EmpiricalTransformer()\n",
    "    else:\n",
    "        transformer = None\n",
    "else:\n",
    "    print('FLEX FORECASTS NOT POSSIBLE WITHOUT MOS')\n",
    "\n",
    "from scipy.stats import norm, t\n",
    "\n",
    "# if the transformer is not none, then we used a y-transform in cpt\n",
    "# therefore we have received a prediction error variance file in \"units\" of (standard normal deviates)^2\n",
    "# and need to transform the forecast mean, in order to calculate probability of exceedance\n",
    "\n",
    "if MOS in ['CCA', 'PCR']:\n",
    "    if transformer is not None:\n",
    "        # we need to normalize the forecast mean here, using the same method as CPT\n",
    "        transformer.fit(Y.expand_dims({'M':[0]}))\n",
    "        fcst_mu = transformer.transform(det_fcst.expand_dims({'M':[0]}))\n",
    "    else:\n",
    "        fcst_mu = det_fcst\n",
    "\n",
    "    if isPercentile:\n",
    "        if transformer is None:\n",
    "            # if the user provided a percentile theshold, rather than an actual value\n",
    "            # and also used no transformation / normalization, \n",
    "            # then we also need to compute the theshold as an actual value\n",
    "            threshold = Y.quantile(threshold, dim='T').drop('quantile')\n",
    "        else:\n",
    "            # if the user used a transformation and gave a percentile threshold, \n",
    "            # we we can set the threshold using the cumulative distribution function \n",
    "            # for the normal distribution N(0, 1)- since thats what the Y data has \n",
    "            # been transformed to\n",
    "            threshold = xr.ones_like(fcst_mu).where(~np.isnan(fcst_mu), other=np.nan) * norm.cdf(threshold)\n",
    "    else:\n",
    "        if transformer is None:\n",
    "            # if the user did not use a transform, and also did not use a percentile for a threshold,\n",
    "            # we can just use the value directly. but it must be expanded to a 2D datatype\n",
    "            threshold = xr.ones_like(fcst_mu).where(~np.isnan(fcst_mu), other=np.nan) * threshold \n",
    "        else: \n",
    "            # if the user used a transformation, but gave a full value and NOT a percentile, \n",
    "            # we must use the transformation that CPT used to transform the threshold onto \n",
    "            # the normal distribution at N(0, 1)\n",
    "            threshold = xr.ones_like(fcst_mu).where(~np.isnan(fcst_mu), other=np.nan) * threshold \n",
    "            threshold = transformer.transform(threshold)\n",
    "    \n",
    "    def _xr_tsf(thrs, loc1, scale1, dof1=1):\n",
    "        return t.sf(thrs, dof1, loc=loc1, scale=scale1)\n",
    "    \n",
    "    ntrain = Y.shape[list(Y.dims).index('T')]\n",
    "    fcst_scale = np.sqrt( (ntrain -2)/ntrain * pev_fcst )\n",
    "    \n",
    "    # if we transformed the forecast data, we should transform the actual Y data to match\n",
    "    if transformer is not None:\n",
    "        Y2 = transformer.transform(Y.expand_dims({'M':[0]})).fillna(Y.min('T')) * xr.ones_like(Y.mean('T')).where(~np.isnan(Y.mean('T')), other=np.nan)\n",
    "        Y2_fill = xr.where(~np.isfinite(Y2), 0, Y2)\n",
    "        Y2 = xr.where(np.isfinite(Y2), Y2, Y2_fill)\n",
    "    else:\n",
    "        Y2 = Y\n",
    "    # here we calculate the climatological mean and variance\n",
    "    climo_var =  Y2.var('T') # xr.ones_like(fcst_mu).where(~np.isnan(fcst_mu), other=np.nan) if transformer is not None else\n",
    "    climo_mu =  Y2.mean('T') # xr.ones_like(fcst_mu).where(~np.isnan(fcst_mu), other=np.nan) if transformer is not None else\n",
    "    climo_scale = np.sqrt( (ntrain -2)/ntrain * climo_var )\n",
    "    \n",
    "    # we calculate here, the probability of exceedance by taking 1 - t.cdf()\n",
    "    # after having transformed the forecast mean to match the units of the \n",
    "    # prediction error variance, if necessary.\n",
    "    exceedance_prob = xr.apply_ufunc( _xr_tsf, threshold, fcst_mu, fcst_scale, input_core_dims=[['X', 'Y'], ['X', 'Y'], ['X', 'Y']], output_core_dims=[['X', 'Y']],keep_attrs=True, kwargs={'dof1':ntrain})\n",
    "\n",
    "exceedance_prob.to_netcdf(case_directory / ('nextgen_exceedance_prob.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1607709",
   "metadata": {},
   "source": [
    "## Now starts the plotting - results are read back from files and plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import xarray as xr \n",
    "import numpy as np \n",
    "import cartopy.crs as ccrs \n",
    "from pathlib import Path \n",
    "\n",
    "case_directory = Path.home() / \"Desktop\" / \"pycpt_debugging\"\n",
    "case_directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "MOS = 'CCA' # must be one of 'CCA', 'PCR', or \"None\"\n",
    "predictor_names = ['CFSv2.PRCP','GEOSS2S.PRCP' ]\n",
    "predictand_name = 'UCSB.PRCP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a189d",
   "metadata": {},
   "source": [
    "# Individual Model Skill Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621de446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPLOTTING SKILL SCORES')\n",
    "skill_metrics = ['pearson', 'spearman', 'generalized_roc', 'rank_probability_skill_score']\n",
    "#cmaps = [plt.get_cmap('cpt.correlation', 11), plt.get_cmap('cpt.correlation', 11), plt.get_cmap('RdBu_r', 11), plt.get_cmap('autumn_r', 11) ]\n",
    "#limits = [(-1, 1), (-1, 1), (0, 100), (-35, 35)]\n",
    "cmaps = [plt.get_cmap('cpt.correlation', 11), plt.get_cmap('cpt.correlation', 11), plt.get_cmap('RdBu_r', 11), plt.get_cmap('cpt.correlation', 11) ]\n",
    "limits = [(-1, 1), (-1, 1), (0, 100), (-50, 50)]\n",
    "\n",
    "missing_value_flag = -999\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(predictor_names), ncols=len(skill_metrics), subplot_kw={'projection':ccrs.PlateCarree()}, figsize=(5*len(skill_metrics), 4*len(predictor_names)))\n",
    "if len(predictor_names) == 1: \n",
    "    ax = [ax]\n",
    "\n",
    "for i, model in enumerate(predictor_names):\n",
    "    for j, skill_metric in enumerate(skill_metrics):\n",
    "        n = getattr(xr.open_dataset(case_directory / (model + '_skillscores_{}.nc')), skill_metric).where(getattr(skill[i], skill_metric) > missing_value_flag).plot(ax=ax[i][j], cmap=cmaps[j], vmin=limits[j][0], vmax=limits[j][1])\n",
    "        ax[i][j].coastlines()\n",
    "        ax[0][j].set_title(skill_metric.upper())\n",
    "\n",
    "    ax[i][0].text(-0.07, 0.55, model.upper(), va='bottom', ha='center', rotation='vertical', rotation_mode='anchor', transform=ax[i][0].transAxes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c2c9e",
   "metadata": {},
   "source": [
    "# Individual Model EOF modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30842ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\nPLOTTING EOF MODES (if MOS==CCA or MOS==PCR)')\n",
    "nmodes = 5\n",
    "cmap= plt.get_cmap('cpt.loadings', 11)\n",
    "vmin=-10\n",
    "vmax = 10\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "if MOS == 'CCA':\n",
    "    for i, model in enumerate(predictor_names):\n",
    "        for mode in range(nmodes):\n",
    "            print(model.upper() + ' - MODE {}'.format(mode+1))\n",
    "            px = xr.open_dataset(case_directory / (model + '_cca_x_spatial_loadings.nc'))\n",
    "            py = xr.open_dataset(case_directory / (model + '_cca_y_spatial_loadings.nc'))\n",
    "\n",
    "            fig = plt.figure(figsize=(20,5))\n",
    "            gs0 = gridspec.GridSpec(1, 3, figure=fig)\n",
    "            gs00 = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=gs0[0])\n",
    "            gs01 = gridspec.GridSpecFromSubplotSpec(4, 5, subplot_spec=gs0[1])\n",
    "            gs02 = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=gs0[2])\n",
    "            ts = xr.concat([px.x_eof_scores.isel(Mode=mode), py.y_eof_scores.isel(Mode=mode)], 'M').assign_coords({'M': ['x', 'y']})\n",
    "            \n",
    "            map1_ax = fig.add_subplot(gs00[:,:], projection = ccrs.PlateCarree())\n",
    "            ts_ax = fig.add_subplot( gs01[1:3,1:])\n",
    "            map2_ax = fig.add_subplot(gs02[:,:], projection = ccrs.PlateCarree())\n",
    "            \n",
    "            px.x_eof_loadings.isel(Mode=mode).where(px.x_eof_loadings.isel(Mode=mode) > missing_value_flag).plot(ax=map1_ax, cmap=cmap)\n",
    "            py.y_eof_loadings.isel(Mode=mode).where(py.y_eof_loadings.isel(Mode=mode) > missing_value_flag).plot(ax=map2_ax, cmap=cmap)\n",
    "\n",
    "            primitive = ts.plot.line(marker='x', ax=ts_ax, markersize=12, hue='M', add_legend=False)\n",
    "            ts_ax.grid(axis = 'x', linestyle = '-.')\n",
    "            ts_ax.legend(handles=primitive, labels = list(ts.coords['M'].values), loc='best')\n",
    "            ts_ax.spines['top'].set_visible(False)\n",
    "            ts_ax.spines['right'].set_visible(False)\n",
    "            ts_ax.spines['bottom'].set_visible(False)\n",
    "            ts_ax.set_title('EOF Scores (Mode {})'.format(mode+1))\n",
    "            ts_ax.set_ylabel(None)\n",
    "            ts_ax.set_xlabel(None)\n",
    "            \n",
    "            map1_ax.set_title('X EOF MODE {}'.format(mode+1))\n",
    "            map2_ax.set_title('Y EOF MODE {}'.format(mode+1))\n",
    "            \n",
    "            map1_ax.coastlines()\n",
    "            map2_ax.coastlines()\n",
    "            plt.show()\n",
    "elif MOS == 'PCR':\n",
    "    for i, model in enumerate(predictor_names):\n",
    "        for mode in range(nmodes):\n",
    "            print(model.upper() + ' - MODE {}'.format(mode+1))\n",
    "            px = xr.open_dataset(case_directory / (model + '_eof_x_spatial_loadings.nc'))\n",
    "\n",
    "            fig = plt.figure(figsize=(20,5))\n",
    "            gs0 = gridspec.GridSpec(1, 3, figure=fig)\n",
    "            gs00 = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=gs0[0])\n",
    "            gs01 = gridspec.GridSpecFromSubplotSpec(4, 5, subplot_spec=gs0[1])\n",
    "            gs02 = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=gs0[2])\n",
    "            ts = xr.concat([pxs[i].x_eof_scores.isel(Mode=mode)], 'M').assign_coords({'M': ['x']})\n",
    "            \n",
    "            map1_ax = fig.add_subplot(gs00[:,:], projection = ccrs.PlateCarree())\n",
    "            ts_ax = fig.add_subplot( gs01[1:3,1:])\n",
    "            map2_ax = fig.add_subplot(gs02[:,:], projection = ccrs.PlateCarree())\n",
    "            \n",
    "            px.x_eof_loadings.isel(Mode=mode).where(px.x_eof_loadings.isel(Mode=mode) > missing_value_flag).plot(ax=map1_ax, cmap=cmap)            #pys[i].y_eof_loadings.isel(Mode=mode).plot(ax=map2_ax, cmap=cmap)\n",
    "\n",
    "            primitive = ts.plot.line(marker='x', ax=ts_ax, markersize=12, hue='M', add_legend=False)\n",
    "            ts_ax.grid(axis = 'x', linestyle = '-.')\n",
    "            ts_ax.legend(handles=primitive, labels = list(ts.coords['M'].values), loc='best')\n",
    "            ts_ax.spines['top'].set_visible(False)\n",
    "            ts_ax.spines['right'].set_visible(False)\n",
    "            ts_ax.spines['bottom'].set_visible(False)\n",
    "            ts_ax.set_title('EOF Scores (Mode {})'.format(mode+1))\n",
    "            ts_ax.set_ylabel(None)\n",
    "            ts_ax.set_xlabel(None)\n",
    "            \n",
    "            map1_ax.set_title('X EOF MODE {}'.format(mode+1))\n",
    "            #map2_ax.set_title('Y EOF MODE {}'.format(mode+1))\n",
    "            \n",
    "            map1_ax.coastlines()\n",
    "            #map2_ax.coastlines()\n",
    "            plt.show()\n",
    "else:\n",
    "    print('You will need to set MOS=CCA or MOS=PCR in order to see any EOF Modes')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904248e",
   "metadata": {},
   "source": [
    "## Individual Model CCA Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\n PLOTTING CCA MODES (If MOS=CCA)')\n",
    "nmodes = 5\n",
    "cmap= plt.get_cmap('cpt.loadings', 11)\n",
    "vmin=-10\n",
    "vmax = 10\n",
    "missing_value_flag = -999\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "if MOS == 'CCA':\n",
    "    for i, model in enumerate(predictor_names):\n",
    "        for mode in range(nmodes):\n",
    "            print(model.upper() + ' - MODE {}'.format(mode+1))\n",
    "            px = xr.open_dataset(case_directory / (model + '_cca_x_spatial_loadings.nc'))\n",
    "            py = xr.open_dataset(case_directory / (model + '_cca_y_spatial_loadings.nc'))\n",
    "\n",
    "            fig = plt.figure(figsize=(20,5))\n",
    "            gs0 = gridspec.GridSpec(1, 3, figure=fig)\n",
    "            gs00 = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=gs0[0])\n",
    "            gs01 = gridspec.GridSpecFromSubplotSpec(4, 5, subplot_spec=gs0[1])\n",
    "            gs02 = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=gs0[2])\n",
    "            ts = xr.concat([px.x_cca_scores.isel(Mode=mode), py.y_cca_scores.isel(Mode=mode)], 'M').assign_coords({'M': ['x', 'y']})\n",
    "            \n",
    "            map1_ax = fig.add_subplot(gs00[:,:], projection = ccrs.PlateCarree())\n",
    "            ts_ax = fig.add_subplot( gs01[1:3,1:])\n",
    "            map2_ax = fig.add_subplot(gs02[:,:], projection = ccrs.PlateCarree())\n",
    "            \n",
    "            px.x_cca_loadings.isel(Mode=mode).where(px.x_cca_loadings.isel(Mode=mode) > missing_value_flag).plot(ax=map1_ax, cmap=cmap)\n",
    "            py.y_cca_loadings.isel(Mode=mode).where(py.y_cca_loadings.isel(Mode=mode) > missing_value_flag).plot(ax=map2_ax, cmap=cmap)\n",
    "\n",
    "            primitive = ts.plot.line(marker='x', ax=ts_ax, markersize=12, hue='M', add_legend=False)\n",
    "            ts_ax.grid(axis = 'x', linestyle = '-.')\n",
    "            ts_ax.legend(handles=primitive, labels = list(ts.coords['M'].values), loc='best')\n",
    "            ts_ax.spines['top'].set_visible(False)\n",
    "            ts_ax.spines['right'].set_visible(False)\n",
    "            ts_ax.spines['bottom'].set_visible(False)\n",
    "            ts_ax.set_title('CCA Scores (Mode {})'.format(mode+1))\n",
    "            ts_ax.set_ylabel(None)\n",
    "            ts_ax.set_xlabel(None)\n",
    "            \n",
    "            map1_ax.set_title('X CCA MODE {}'.format(mode+1))\n",
    "            map2_ax.set_title('Y CCA MODE {}'.format(mode+1))\n",
    "            \n",
    "            map1_ax.coastlines()\n",
    "            map2_ax.coastlines()\n",
    "            plt.show()\n",
    "else:\n",
    "    print('You will need to set MOS=CCA in order to see CCA Modes') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36537e0",
   "metadata": {},
   "source": [
    "## Individual Model Real-Time Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b391c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPLOTTING REAL-TIME FORECASTS ')\n",
    "missing_value_flag = -999\n",
    "prob_missing_value_flag = -1\n",
    "for i in range(len(predictor_names)):\n",
    "    print(predictor_names[i].upper())\n",
    "    fcst = xr.open_dataset(case_directory / (model + '_realtime_cca_forecasts.nc'))\n",
    "    X = fcst.probabilistic.where(fcst.probabilistic > prob_missing_value_flag).rename({'C':'M'}).isel(T=-1) / 100)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 9), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    bounds = [40,45,50,55,60,65,70,75,80]\n",
    "    nbounds = [40,45,50]\n",
    "    mask = X.mean(x_feature_dim)\n",
    "    mask = mask.where(np.isnan(mask), other=1)\n",
    "    argmax = X.fillna(-999).argmax('M') * mask\n",
    "    \n",
    "    flat = mask.where(argmax != 2, other=X.isel(M=2))\n",
    "    flat = flat.where(argmax != 1, other=X.isel(M=1))\n",
    "    flat = flat.where(argmax != 0, other=X.isel(M=0)) * mask \n",
    "\n",
    "    CS3 = flat.where(argmax == 2, other=np.nan).plot(ax=ax, add_colorbar=False, vmin=0.35, vmax=0.85, cmap=plt.get_cmap('Blues_r', 9))\n",
    "    CS1 = flat.where(argmax == 0, other=np.nan).plot(ax=ax, add_colorbar=False, vmin=0.35, vmax=0.85, cmap=plt.get_cmap('RdBn', 9))\n",
    "    CS2 = flat.where(argmax == 1, other=np.nan).plot(ax=ax, add_colorbar=False, vmin=0.35, vmax=0.55, cmap=plt.get_cmap('Grays_r', 5))\n",
    "\n",
    "    ax.coastlines()\n",
    "    axins_f_bottom = inset_axes(ax, width=\"35%\", height=\"5%\", loc='lower left', bbox_to_anchor=(-0, -0.15, 1, 1), bbox_transform=ax.transAxes,borderpad=0.1 )\n",
    "    axins2_bottom = inset_axes(ax, width=\"20%\",  height=\"5%\", loc='lower center', bbox_to_anchor=(-0.0, -0.15, 1, 1), bbox_transform=ax.transAxes, borderpad=0.1 )\n",
    "    axins3_bottom = inset_axes(ax, width=\"35%\",  height=\"5%\", loc='lower right', bbox_to_anchor=(0, -0.15, 1, 1), bbox_transform=ax.transAxes, borderpad=0.1 )\n",
    "\n",
    "\n",
    "    cbar_fbl = fig.colorbar(CS1, ax=ax, cax=axins_f_bottom, orientation='horizontal')\n",
    "    cbar_fbl.set_label('BN (%)') \n",
    "    cbar_fbl.set_ticks([i /100.0 for i in bounds])\n",
    "    cbar_fbl.set_ticklabels(bounds)\n",
    "\n",
    "\n",
    "    cbar_fbc = fig.colorbar(CS2, ax=ax,  cax=axins2_bottom, orientation='horizontal')\n",
    "    cbar_fbc.set_label('NN (%)') \n",
    "    cbar_fbc.set_ticks([i /100.0 for i in nbounds])\n",
    "    cbar_fbc.set_ticklabels(nbounds)\n",
    "\n",
    "    cbar_fbr = fig.colorbar(CS3, ax=ax,  cax=axins3_bottom, orientation='horizontal')\n",
    "    cbar_fbr.set_label('AN (%)') \n",
    "    cbar_fbr.set_ticks([i /100.0 for i in bounds])\n",
    "    cbar_fbr.set_ticklabels(bounds)\n",
    "    plt.show()\n",
    "    \n",
    "    art = fcst.deterministic.where(fcst.deterministic > missing_value_flag).isel(T=-1).plot(subplot_kws={'projection': ccrs.PlateCarree()}, cmap='Blues', vmin=0)\n",
    "    art.axes.coastlines()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c85d82",
   "metadata": {},
   "source": [
    "# NextGen Ensemble Skill Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd15a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPLOTTING ENSEMBLE SKILL SCORES')\n",
    "skill_metrics = ['pearson', 'spearman', 'generalized_roc', 'rank_probability_skill_score']\n",
    "#cmaps = [plt.get_cmap('RdBu', 11), plt.get_cmap('RdBu', 11), plt.get_cmap('autumn_r', 10), plt.get_cmap('autumn_r', 11) ]\n",
    "#limits = [(-1, 1), (-1, 1), (50, 100), (0, 50)]\n",
    "cmaps = [plt.get_cmap('cpt.correlation', 11), plt.get_cmap('cpt.correlation', 11), plt.get_cmap('RdBu_r', 10), plt.get_cmap('cpt.correlation', 11) ]\n",
    "limits = [(-1, 1), (-1, 1), (0, 100), (-50, 50)]\n",
    "cmaps[2].set_under('lightgray')\n",
    "cmaps[3].set_under('lightgray')\n",
    "\n",
    "nextgen_skill = xr.open_dataset(case_directory / ('nextgen_skillscores.nc'))\n",
    "## Do not modify below\n",
    "fig, ax = plt.subplots(nrows=len(skill_metrics), ncols=1, subplot_kw={'projection':ccrs.PlateCarree()}, figsize=(4, 5*len(skill_metrics)))\n",
    "for j, skill_metric in enumerate(skill_metrics):\n",
    "    ax[j].set_title(skill_metric)\n",
    "    getattr(nextgen_skill, skill_metric).where(getattr(nextgen_skill, skill_metric) > missing_value_flag).plot(ax=ax[j], cmap=cmaps[j], vmin=limits[j][0], vmax=limits[j][1])\n",
    "    ax[j].coastlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d64876",
   "metadata": {},
   "source": [
    "# NextGen Ensemble Real-Time Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PLOTTING ENSEMBLE REAL-TIME FORECASTS')\n",
    "missing_value_flag = -999\n",
    "prob_missing_value_flag = -1 \n",
    "\n",
    "\n",
    "pr_fcst = xr.open_dataset(case_directory / ('nextgen_probabilistic_forecast.nc'))\n",
    "pr_fcst = getattr(pr_fcst, [i for i in pr_fcst.data_vars][0])\n",
    "\n",
    "det_fcst = xr.open_dataset(case_directory / ('nextgen_deterministic_forecast.nc'))\n",
    "det_fcst = getattr(det_fcst, [i for i in det_fcst.data_vars][0])\n",
    "\n",
    "X = pr_fcst.where(pr_fcst > prob_missing_value_flag).rename({'C':'M'}).isel(T=-1) / 100\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 9), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "bounds = [40,45,50,55,60,65,70,75,80]\n",
    "nbounds = [40,45,50]\n",
    "mask = X.mean(x_feature_dim)\n",
    "mask = mask.where(np.isnan(mask), other=1)\n",
    "argmax = X.fillna(-999).argmax('M') * mask\n",
    "\n",
    "flat = mask.where(argmax != 2, other=X.isel(M=2))\n",
    "flat = flat.where(argmax != 1, other=X.isel(M=1))\n",
    "flat = flat.where(argmax != 0, other=X.isel(M=0)) * mask \n",
    "\n",
    "CS3 = flat.where(argmax == 2, other=np.nan).plot(ax=ax, add_colorbar=False, vmin=0.35, vmax=0.85, cmap=plt.get_cmap('Blues_r', 9))\n",
    "CS1 = flat.where(argmax == 0, other=np.nan).plot(ax=ax, add_colorbar=False, vmin=0.35, vmax=0.85, cmap=plt.get_cmap('RdBn', 9))\n",
    "CS2 = flat.where(argmax == 1, other=np.nan).plot(ax=ax, add_colorbar=False, vmin=0.35, vmax=0.55, cmap=plt.get_cmap('Grays_r', 5))\n",
    "\n",
    "ax.coastlines()\n",
    "axins_f_bottom = inset_axes(ax, width=\"35%\", height=\"5%\", loc='lower left', bbox_to_anchor=(-0, -0.15, 1, 1), bbox_transform=ax.transAxes,borderpad=0.1 )\n",
    "axins2_bottom = inset_axes(ax, width=\"20%\",  height=\"5%\", loc='lower center', bbox_to_anchor=(-0.0, -0.15, 1, 1), bbox_transform=ax.transAxes, borderpad=0.1 )\n",
    "axins3_bottom = inset_axes(ax, width=\"35%\",  height=\"5%\", loc='lower right', bbox_to_anchor=(0, -0.15, 1, 1), bbox_transform=ax.transAxes, borderpad=0.1 )\n",
    "\n",
    "\n",
    "cbar_fbl = fig.colorbar(CS1, ax=ax, cax=axins_f_bottom, orientation='horizontal')\n",
    "cbar_fbl.set_label('BN (%)') \n",
    "cbar_fbl.set_ticks([i /100.0 for i in bounds])\n",
    "cbar_fbl.set_ticklabels(bounds)\n",
    "\n",
    "\n",
    "cbar_fbc = fig.colorbar(CS2, ax=ax,  cax=axins2_bottom, orientation='horizontal')\n",
    "cbar_fbc.set_label('NN (%)') \n",
    "cbar_fbc.set_ticks([i /100.0 for i in nbounds])\n",
    "cbar_fbc.set_ticklabels(nbounds)\n",
    "\n",
    "cbar_fbr = fig.colorbar(CS3, ax=ax,  cax=axins3_bottom, orientation='horizontal')\n",
    "cbar_fbr.set_label('AN (%)') \n",
    "cbar_fbr.set_ticks([i /100.0 for i in bounds])\n",
    "cbar_fbr.set_ticklabels(bounds)\n",
    "plt.show()\n",
    "plt.show()\n",
    "art = det_fcst.where(det_fcst > missing_value_flag).isel(T=-1).plot(subplot_kws={'projection': ccrs.PlateCarree()}, cmap='Blues', vmin=0)\n",
    "art.axes.coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be45579",
   "metadata": {},
   "source": [
    "# Exceedance Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd79b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "exceedance_prob = xr.open_dataset(case_directory / ('nextgen_exceedance_prob.nc'))\n",
    "exceedance_prob = getattr(exceedance_prob, [i for i in exceedance_prob.data_vars][0])\n",
    "\n",
    "\n",
    "\n",
    "print('\\nPLOTTING POEs, PDFs, and CDFs ')\n",
    "cmap=plt.get_cmap('RdBu_r', 11)\n",
    "\n",
    "\n",
    "# setting up canvas on which to draw\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "gs0 = gridspec.GridSpec(4, 1, figure=fig)\n",
    "gs00 = gridspec.GridSpecFromSubplotSpec(5, 5, subplot_spec=gs0[:3])\n",
    "gs11 = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=gs0[3])\n",
    "gs01 = gridspec.GridSpecFromSubplotSpec(5, 5, subplot_spec=gs11[0])\n",
    "gs02 = gridspec.GridSpecFromSubplotSpec(5, 5, subplot_spec=gs11[1])\n",
    "\n",
    "map_ax = fig.add_subplot(gs00[:,:], projection = ccrs.PlateCarree())\n",
    "cdf_ax = fig.add_subplot(gs01[:,:])     \n",
    "pdf_ax = fig.add_subplot(gs02[:,:])     \n",
    "\n",
    "#plot the map\n",
    "art = exceedance_prob.transpose('Y', 'X', ...).plot(cmap=cmap,  ax=map_ax, vmin=0, vmax=1) \n",
    "map_ax.scatter([point_longitude], [point_latitude], marker='x', s=100, color='red', transform=ccrs.PlateCarree())\n",
    "coasts = art.axes.coastlines()\n",
    "\n",
    "# point calculations - select the nearest point to the lat/lon the user wanted to plot curves\n",
    "#point_threshold = float(threshold.sel(**{'X':point_longitude, 'Y':point_latitude}, method='nearest').values)\n",
    "#point_fcst_scale = float(fcst_scale.sel(**{'X':point_longitude, 'Y':point_latitude}, method='nearest').values)\n",
    "#point_climo_scale = float(climo_scale.sel(**{'X':point_longitude, 'Y':point_latitude}, method='nearest').values)\n",
    "#point_fcst_mu = float(fcst_mu.sel(**{'X':point_longitude, 'Y':point_latitude}, method='nearest').values)\n",
    "#point_climo_mu = float(climo_mu.sel(**{'X':point_longitude, 'Y':point_latitude}, method='nearest').values)\n",
    "#point_climo = np.squeeze(Y2.sel(**{'X':point_longitude, 'Y':point_latitude}, method='nearest').values)\n",
    "#point_climo.sort()\n",
    "\n",
    "#if transformer is not None:\n",
    "#    point_climo_mu_nontransformed = float(Y.mean('T').sel(**{'X':point_longitude, 'Y':point_latitude}, method='nearest').values)\n",
    "#    point_climo_std_nontransformed = float(Y.std('T').sel(**{'X':point_longitude, 'Y':point_latitude}, method='nearest').values)\n",
    "\n",
    "\n",
    "#x = point_climo \n",
    "#x1 =np.linspace(x.min(), x.max(), 1000)\n",
    "#cprobth =  sum(x >= point_threshold) / x.shape[0]  #round(t.sf(point_threshold, ntrain, loc=point_climo_mu, scale=point_climo_scale),2)\n",
    "#fprobth = round(t.sf(point_threshold, ntrain, loc=point_fcst_mu, scale=point_fcst_scale),2)\n",
    "\n",
    "\n",
    "\n",
    "#cdf_ax.plot(x, [ sum(x >= x[i]) / x.shape[0] for i in range(x.shape[0]) ],'b-', lw=2, marker='x', alpha=0.8, label='clim (emp)')\n",
    "#cdf_ax.plot(x1, t.sf(x1, ntrain, loc=point_fcst_mu, scale=point_fcst_scale),'r-',  lw=1, alpha=0.8, label='fcst')\n",
    "#cdf_ax.plot(x1, norm.sf(x1, loc=point_climo_mu, scale=point_fcst_scale),'g-', lw=1, alpha=0.8, label='clim (fitted)')\n",
    "\n",
    "\n",
    "#cdf_ax.plot(point_threshold, fprobth,'ok')\n",
    "#cdf_ax.plot(point_threshold, cprobth,'ok')\n",
    "#cdf_ax.axvline(x=point_threshold, color='k', linestyle='--')\n",
    "#cdf_ax.set_title('Probabilities of Exceedance')\n",
    "#cdf_ax.set_xlabel(Y.name.upper())\n",
    "#cdf_ax.set_ylabel('Probability (%)')\n",
    "#cdf_ax.legend(loc='best', frameon=False)\n",
    "\n",
    "#fpdf=t.pdf(x1, ntrain, loc=point_fcst_mu, scale=np.sqrt(point_fcst_scale))\n",
    "#pdf_ax.plot(x1, norm.pdf(x1, loc=point_climo_mu, scale =point_climo_scale), 'b-', alpha=0.8, label='clim (fitted)')\n",
    "#pdf_ax.plot(x1, fpdf, 'r-',  alpha=0.8, label='fcst')\n",
    "#pdf_ax.hist(point_climo, density=True, histtype='step', label='clim')\n",
    "\n",
    "#pdf_ax.axvline(x=point_threshold, color='k', linestyle='--')\n",
    "#pdf_ax.legend(loc='best', frameon=False)\n",
    "#pdf_ax.set_title('Probability Density Functions')\n",
    "#pdf_ax.set_xlabel(Y.name.upper())\n",
    "#pdf_ax.set_ylabel('')\n",
    "\n",
    "#if transformer is not None:\n",
    "#    newticks = [-2, -1, 0, 1, 2]\n",
    "#    pdf_ax.set_xticks(newticks, [round(i * point_climo_std_nontransformed + point_climo_mu_nontransformed, 2) for i in newticks], rotation=0)\n",
    "#    cdf_ax.set_xticks(newticks, [round(i * point_climo_std_nontransformed + point_climo_mu_nontransformed, 2) for i in newticks], rotation=0)\n",
    "\n",
    "#title = map_ax.set_title('Probabilities of Exceedance')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "pycpt",
   "language": "python",
   "name": "pycpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
